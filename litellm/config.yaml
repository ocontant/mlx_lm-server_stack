include:
  - models_config.yaml

general_settings:
  allowed_model_names: ["*"]
  openai_api_base: /v1
  # background_health_checks: True  # enable background health checks
  # health_check_interval: 300s     # frequency of background health checks
  litellm_log: DEBUG

  # Pass-through endpoints configuration
  general_settings:
    pass_through_endpoints:
      - path: "/v1/messages"
        target: "app.litellm.llms.anthropic.converter.adapters.anthropic_to_openai_adapter"

litellm_settings:
  json_logs: true

pass_through_credentials:
  anthropic:
    api_key: not-needed

router_settings:
  cooldown_time: 10
  disable_cooldowns: False
  routing_strategy: usage-based

  # Custom logger for the adapter
  custom_logger:
    anthropic:
      path: "app.litellm.llms.anthropic.converter.adapters.anthropic_to_openai_adapter.anthropic_to_openai_adapter"

  # Pass-through routes
  pass_through_routes:
    "/v1/messages": "anthropic"

  api_aliases:
    /v1/complete: /v1/chat/completions
    /v1/generateContent: /v1/chat/completions
    /v1/generate: /v1/chat/completions
    /embeddings: /v1/embeddings

  aliases:
    # OpenAI
    claude-3-7-sonnet-20250219: qwen2.5-coder-3b-instruct
    
server_settings:
  host: 0.0.0.0
  port: 4000
  cors_allow_origins: ["*"]
  cors_allow_methods: ["*"]
  cors_allow_headers: ["*"]
